{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "#!pip install tensorflow-gpu==2.0.0-beta0\n",
    "#!pip install tensorflow_hub\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "Found 1289 images belonging to 6 classes.\n",
      "Found 5169 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "data_root='data/'\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "TRAINING_DATA_DIR = str(data_root)\n",
    "print(TRAINING_DATA_DIR);\n",
    "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
    "#datagen_kwargs_train = dict(rescale=1./255)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    TRAINING_DATA_DIR, \n",
    "    subset=\"validation\", \n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SHAPE\n",
    ")\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DATA_DIR, \n",
    "    subset=\"training\", \n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\1652\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     multiple                  5327773   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  240480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  28920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  726       \n",
      "=================================================================\n",
      "Total params: 5,597,899\n",
      "Trainable params: 270,126\n",
      "Non-trainable params: 5,327,773\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_88 = tf.keras.Sequential([\n",
    "  hub.KerasLayer(\"model/\"),\n",
    "  tf.keras.layers.Dense(train_generator.num_classes*40, activation='softmax'),\n",
    "  tf.keras.layers.Dense(train_generator.num_classes*20, activation='softmax'),\n",
    "  tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "\n",
    "])\n",
    "model_88.build([None,224,224,3])\n",
    "\n",
    "model_88.summary()\n",
    "model_88.compile(\n",
    "  optimizer=tf.keras.optimizers.Adamax(),\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "161/162 [============================>.] - ETA: 0s - loss: 1.7919 - acc: 0.1542Epoch 1/2\n",
      "162/162 [==============================] - 75s 460ms/step - loss: 1.7919 - acc: 0.1538 - val_loss: 1.7920 - val_acc: 0.1536\n",
      "Epoch 2/2\n",
      "161/162 [============================>.] - ETA: 0s - loss: 1.7918 - acc: 0.1532Epoch 1/2\n",
      "162/162 [==============================] - 74s 459ms/step - loss: 1.7917 - acc: 0.1538 - val_loss: 1.7917 - val_acc: 0.1536\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
    "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
    "hist = model_88.fit(\n",
    "    train_generator, \n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "# 保存模型结构到yaml文件或者json文件\n",
    "yaml_string = model_88.to_yaml()\n",
    "open('model_architecture_choosed.yaml', 'w').write(yaml_string)\n",
    "# json_string = model.to_json()\n",
    "# open('../docs/keras/model_architecture.json', 'w').write(json_string)\n",
    "\n",
    "# 保存模型参数到h5文件\n",
    "model_88.save_weights('model_weights_choosed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.python.keras.models import model_from_yaml\n",
    "\n",
    "# 加载模型结构\n",
    "model00 = model_from_yaml(open('model_architecture_choosed.yaml').read(),custom_objects={'KerasLayer': KerasLayer})\n",
    "# model = model_from_json(open('../docs/keras/model_architecture.json').read())\n",
    "\n",
    "# 加载模型参数\n",
    "model00.load_weights('model_weights_choosed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasLayer(tf.keras.layers.Layer):\n",
    "  \"\"\"Wraps a SavedModel (or a legacy TF1 Hub format) as a Keras Layer.\n",
    "  This layer wraps a callable object for use as a Keras layer. The callable\n",
    "  object can be passed directly, or be specified by a Python string with a\n",
    "  handle that gets passed to `hub.load()`.\n",
    "  This is the preferred API to load a TF2-style SavedModel from TF Hub\n",
    "  into a Keras model. Calling this function requires TF 1.15 or newer.\n",
    "  It can be called both in eager and graph mode.\n",
    "  The callable object is expected to follow the conventions detailed below.\n",
    "  (These are met by TF2-compatible modules loaded from TensorFlow Hub.)\n",
    "  The callable is invoked with a single positional argument set to one tensor\n",
    "  or a nest of tensors containing the inputs to the layer. If the callable\n",
    "  accepts a `training` argument, a Python boolean is passed for it. It is True\n",
    "  if this layer is marked trainable *and* called for training.\n",
    "  If present, the following attributes of callable are understood to have\n",
    "  special meanings:\n",
    "    variables: a list of all tf.Variable objects that the callable depends on.\n",
    "    trainable_variables: those elements of `variables` that are reported\n",
    "      as trainable variables of this Keras Layer when the layer is trainable.\n",
    "    regularization_losses: a list of callables to be added as losses of this\n",
    "      Keras Layer when the layer is trainable. Each one must accept zero\n",
    "      arguments and return a scalar tensor.\n",
    "  Note: to work-around missing shape inference functionalities from functions\n",
    "  created from FunctionDefs, in rare cases one has to pass an 'output_shape'\n",
    "  and potentially 'input_shape' and 'dtype'. E.g. the following is a typical\n",
    "  work-around:\n",
    "  ```\n",
    "  hub.KerasLayer(\n",
    "      \"/tmp/text_embedding_model\",\n",
    "      output_shape=[20],  # Outputs a tensor with shape [batch_size, 20].\n",
    "      input_shape=[],     # Expects a tensor of shape [batch_size] as input.\n",
    "      dtype=tf.string)    # Expects a tf.string input tensor.\n",
    "  ```\n",
    "  Note: This layer can be used inside the model_fn of a TF2 Estimator. See the\n",
    "  [migration guide]\n",
    "  (https://www.tensorflow.org/beta/guide/migration_guide#using_a_custom_model_fn)\n",
    "  for guidance on how to pick up trainable variables, losses and updates\n",
    "  explicitly from Keras objects instead of relying on graph collections.\n",
    "  This layer class does not support graph collections.\n",
    "  Distributed training of the Estimator requires setting the option\n",
    "  `session_config.share_cluster_devices_in_session` within the\n",
    "  `tf.estimator.RunConfig`. (This option was experimental from TF1.14 to TF2.1.)\n",
    "  Note: The data types used by a saved model have been fixed at saving time.\n",
    "  Using tf.keras.mixed_precision etc. has no effect on the saved model\n",
    "  that gets loaded by a hub.KerasLayer.\n",
    "  Attributes:\n",
    "    handle: A callable object (subject to the conventions above), or a Python\n",
    "      string to load a saved model via hub.load(). A string is required to save\n",
    "      the Keras config of this Layer.\n",
    "    trainable: Optional. A boolean controlling whether this layer is trainable.\n",
    "      Must not be set to True when using a signature (raises ValueError),\n",
    "      including the use of legacy TF1 Hub format.\n",
    "    arguments: Optional. A dict with additional keyword arguments passed to the\n",
    "      callable. These must be JSON-serializable to save the Keras config of this\n",
    "      layer, and are not tracked as checkpointing dependencies of this layer.\n",
    "    _sentinel: Used to prevent further positional arguments.\n",
    "    tags: Optional. If set indicates which graph variant to use. For legacy\n",
    "      models in TF1 Hub format leaving unset means to use the empty tags set.\n",
    "    signature: Optional. If set, KerasLayer will use the requested signature.\n",
    "      For legacy models in TF1 Hub format leaving unset means to use the\n",
    "      `default` signature. When using a signature, either\n",
    "      signature_outputs_as_dict or output_key have to set.\n",
    "    signature_outputs_as_dict: If set to True, the call to this layer returns a\n",
    "      dict of all the signature outputs. Can only be used if a signature is\n",
    "      specified (or default signature is used for legacy models in TF1 Hub\n",
    "      format).\n",
    "    output_key: Name of the output item to return if the layer returns a dict.\n",
    "      For legacy models in TF1 Hub format leaving unset means to return the\n",
    "      `default` output.\n",
    "    output_shape: A tuple or a nest of tuples with the (possibly partial) output\n",
    "      shapes of the callable *without* leading batch size. This must have the\n",
    "      same nesting structure as the output of the callable object and cover all\n",
    "      output tensors.\n",
    "    load_options: Optional, `tf.saved_model.LoadOptions` object that specifies\n",
    "      options for loading when a Python string is provided as `handle`. This\n",
    "      argument can only be used from TensorFlow 2.3 onwards.\n",
    "    **kwargs: Forwarded to Keras' base Layer constructor.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      handle,\n",
    "      trainable=False,\n",
    "      arguments=None,\n",
    "      _sentinel=None,  # pylint: disable=invalid-name\n",
    "      tags=None,\n",
    "      signature=None,\n",
    "      signature_outputs_as_dict=None,\n",
    "      output_key=None,\n",
    "      output_shape=None,\n",
    "      load_options=None,\n",
    "      **kwargs):\n",
    "    # Note: for compatibility with keras-model serialization this layer is\n",
    "    # json-serializable. If you add or change arguments here, please also update\n",
    "    # the `get_config` method.\n",
    "    # The arguments are marked NoDependency to avoid autoconversion to a\n",
    "    # trackable _DictWrapper, because that upsets json.dumps() when saving\n",
    "    # the result of get_config().\n",
    "    self._handle = handle\n",
    "    self._arguments = data_structures.NoDependency(arguments or {})\n",
    "    self._signature = signature\n",
    "    self._signature_outputs_as_dict = signature_outputs_as_dict\n",
    "    self._output_key = output_key\n",
    "    # TODO(b/142213824): Remove setting shapes when shape inference works.\n",
    "    if output_shape:\n",
    "      # Autograph chokes on _convert_nest_to_shapes(), so we call it here\n",
    "      # and not from within call().\n",
    "      self._output_shape = data_structures.NoDependency(\n",
    "          _convert_nest_to_shapes(output_shape))\n",
    "\n",
    "    self._load_options = load_options\n",
    "    self._func = load_module(handle, tags, self._load_options)\n",
    "    self._has_training_argument = func_has_training_argument(self._func)\n",
    "    self._is_hub_module_v1 = getattr(self._func, \"_is_hub_module_v1\", False)\n",
    "\n",
    "    # Update with the defaults when using legacy TF1 Hub format.\n",
    "    if self._is_hub_module_v1:\n",
    "      self._signature = self._signature or \"default\"\n",
    "      if not self._signature_outputs_as_dict:\n",
    "        self._output_key = self._output_key or \"default\"\n",
    "    # More validity checks.\n",
    "    if self._signature and (bool(self._output_key is not None)\n",
    "                            == bool(self._signature_outputs_as_dict)):\n",
    "      raise ValueError(\"When using a signature, either output_key or \"\n",
    "                       \"signature_outputs_as_dict=True should be set.\")\n",
    "    if not self._signature and self._signature_outputs_as_dict:\n",
    "      raise ValueError(\"signature_outputs_as_dict is only valid if specifying \"\n",
    "                       \"a signature (or using a legacy TF1 Hub format).\")\n",
    "\n",
    "    self._callable = self._get_callable()\n",
    "    self._setup_layer(trainable, **kwargs)\n",
    "\n",
    "  def _setup_layer(self, trainable=False, **kwargs):\n",
    "    \"\"\"Constructs keras layer with relevant weights and losses.\"\"\"\n",
    "    # Initialize an empty layer, then add_weight() etc. as needed.\n",
    "    super(KerasLayer, self).__init__(trainable=trainable, **kwargs)\n",
    "\n",
    "    # Add trainable and non-trainable weights from the callable.\n",
    "    if hasattr(self._func, \"trainable_variables\"):\n",
    "      for v in self._func.trainable_variables:\n",
    "        self._add_existing_weight(v, trainable=True)\n",
    "      trainable_variables = {id(v) for v in self._func.trainable_variables}\n",
    "    else:\n",
    "      trainable_variables = set()\n",
    "    if hasattr(self._func, \"variables\"):\n",
    "      for v in self._func.variables:\n",
    "        if id(v) not in trainable_variables:\n",
    "          self._add_existing_weight(v, trainable=False)\n",
    "\n",
    "    # Forward the callable's regularization losses (if any).\n",
    "    if hasattr(self._func, \"regularization_losses\"):\n",
    "      for l in self._func.regularization_losses:\n",
    "        if not callable(l):\n",
    "          raise ValueError(\n",
    "              \"hub.KerasLayer(obj) expects obj.regularization_losses to be an \"\n",
    "              \"iterable of callables, each returning a scalar loss term.\")\n",
    "        self.add_loss(self._call_loss_if_trainable(l))  # Supports callables.\n",
    "\n",
    "  def _add_existing_weight(self, weight, trainable=None):\n",
    "    \"\"\"Calls add_weight() to register but not create an existing weight.\"\"\"\n",
    "    if trainable is None: trainable = weight.trainable\n",
    "    self.add_weight(name=weight.name, shape=weight.shape, dtype=weight.dtype,\n",
    "                    trainable=trainable, getter=lambda *_, **__: weight)\n",
    "\n",
    "  def _call_loss_if_trainable(self, loss):\n",
    "    \"\"\"Returns `loss` conditioned on whether this layer is trainable.\"\"\"\n",
    "    return lambda: loss() if self.trainable else 0.\n",
    "\n",
    "  def call(self, inputs, training=None):\n",
    "    # These checks happen here and not in __init__, because self.trainable is\n",
    "    # a mutable public attribute.\n",
    "    self._check_trainability()\n",
    "\n",
    "    # We basically want to call this...\n",
    "    args = []\n",
    "    kwargs = self._arguments.copy()\n",
    "    if self._signature and isinstance(inputs, dict):\n",
    "      kwargs.update(inputs)\n",
    "    else:\n",
    "      args.append(inputs)\n",
    "    f = functools.partial(self._callable, *args, **kwargs)\n",
    "    # ...but we may also have to pass a Python boolean for `training`, which\n",
    "    # is the logical \"and\" of this layer's trainability and what the surrounding\n",
    "    # model is doing (analogous to tf.keras.layers.BatchNormalization in TF2).\n",
    "    # For the latter, we have to look in two places: the `training` argument,\n",
    "    # or else Keras' global `learning_phase`, which might actually be a tensor.\n",
    "    if not self._has_training_argument:\n",
    "      result = f()\n",
    "    else:\n",
    "      if self.trainable:\n",
    "        if training is None:\n",
    "          training = tf.keras.backend.learning_phase()\n",
    "      else:\n",
    "        training = False\n",
    "      result = smart_cond.smart_cond(training,\n",
    "                                     lambda: f(training=True),\n",
    "                                     lambda: f(training=False))\n",
    "\n",
    "    # Unwrap dicts returned by signatures.\n",
    "    if self._output_key:\n",
    "      if not isinstance(result, dict):\n",
    "        raise ValueError(\"Specifying `output_key` is forbidden if output \"\n",
    "                         \"type %s is not a dict.\" % type(result))\n",
    "      if self._output_key not in result:\n",
    "        raise ValueError(\n",
    "            \"KerasLayer output does not contain the output key %s \"\n",
    "            \"(available: %s).\" % (self._output_key, result.keys()))\n",
    "      result = result[self._output_key]\n",
    "\n",
    "    # TODO(b/142213824): Remove setting shapes when shape inference works.\n",
    "    result = self._apply_output_shape_if_set(inputs, result)\n",
    "    return result\n",
    "\n",
    "  def _check_trainability(self):\n",
    "    \"\"\"Raises or logs errors for unuspported uses of trainable=True.\"\"\"\n",
    "    if not self.trainable: return  # Nothing to do.\n",
    "\n",
    "    # Training is only supported when calling a reusable TF2 SavedModel through\n",
    "    # its @tf.function __call__. Trying to train through a signature is likely\n",
    "    # to go wrong beyond the most simple cases due to a number of pitfalls:\n",
    "    # - No good support for train vs inference mode. TF1 Hub format used\n",
    "    #   graph versions identified by tags, but this was not a general\n",
    "    #   standard for SavedModels, and TF2 can no longer save with tags.\n",
    "    # - No support for update ops. TF1 Hub format had them in the UPDATE_OPS\n",
    "    #   collection, but collections are no longer loaded in TF2. General\n",
    "    #   SavedModel signatures had no support for them.\n",
    "    # - No support for regularization losses (same story).\n",
    "    # - A SavedModel without @tf.function __call__ will likely also not\n",
    "    #   provide a trainable_variables attribute.\n",
    "    if self._is_hub_module_v1:\n",
    "      raise ValueError(\n",
    "          \"Setting hub.KerasLayer.trainable = True is unsupported when \"\n",
    "          \"loading from the TF1 Hub format.\")\n",
    "    elif self._signature:\n",
    "      raise ValueError(\n",
    "          \"Setting hub.KerasLayer.trainable = True is unsupported when \"\n",
    "          \"calling a SavedModel signature.\")\n",
    "    # Having zero trainable variables in an otherwise trainable model\n",
    "    # is suspicious but may be valid as a boundary case, so we just log,\n",
    "    # but at most once per layer instance.\n",
    "    if not self.trainable_weights:\n",
    "      if not hasattr(self, \"_already_logged_trainable_with_zero_weights\"):\n",
    "        logging.error(\n",
    "            \"hub.KerasLayer is trainable but has zero trainable weights.\")\n",
    "        setattr(self, \"_already_logged_trainable_with_zero_weights\", True)\n",
    "\n",
    "  def _get_callable(self):\n",
    "    \"\"\"Returns a callable object.\"\"\"\n",
    "    if callable(self._func) and not self._signature:\n",
    "      return self._func\n",
    "    if not hasattr(self._func, \"signatures\"):\n",
    "      if self._signature:  # Assuming the user intended to use a signature.\n",
    "        raise ValueError(\"Loaded object has no signatures.\")\n",
    "      else:  # Assuming the user intended to use a callable SavedModel.\n",
    "        raise ValueError(\n",
    "            \"Loaded object is not callable and has no signatures.\")\n",
    "    if self._signature is None:\n",
    "      raise ValueError(\"Signature name has to be specified for non-callable \"\n",
    "                       \"saved models (if not legacy TF1 Hub format).\")\n",
    "    if self._signature not in self._func.signatures:\n",
    "      raise ValueError(\"Unknown signature %s in %s (available signatures: %s).\"\n",
    "                       % (self._signature, self._handle, self._func.signatures))\n",
    "    f = self._func.signatures[self._signature]\n",
    "    if not callable(f):\n",
    "      raise ValueError(\"Internal error: signature %s is not callable in %s\" %\n",
    "                       (self._signature, self._handle))\n",
    "    return f\n",
    "\n",
    "  def _apply_output_shape_if_set(self, inputs, outputs):\n",
    "    if not hasattr(self, \"_output_shape\"):\n",
    "      return outputs\n",
    "    # Traverse the nest and turn shape-like tuples into tf.TensorShapes,\n",
    "    # or else map_structure below would try to recurse into them.\n",
    "    output_shape = getattr(self, \"_output_shape\")\n",
    "    batch_size = tf.nest.flatten(inputs)[0].shape[0]\n",
    "    def _inplace_set_shape(tensor, shape):\n",
    "      tensor.set_shape(tf.TensorShape(batch_size).concatenate(shape))\n",
    "    tf.nest.map_structure(_inplace_set_shape, outputs, output_shape)\n",
    "    return outputs\n",
    "\n",
    "  def get_config(self):\n",
    "    \"\"\"Returns a serializable dict of keras layer configuration parameters.\"\"\"\n",
    "    config = super(KerasLayer, self).get_config()\n",
    "    if not isinstance(self._handle, str):\n",
    "      # Need to raise this type in order for tf.saved_model.save() to fall back\n",
    "      # to not using config, instead of crashing.\n",
    "      # TODO(b/134528831): Reconsider the usability implications.\n",
    "      raise NotImplementedError(\n",
    "          \"Can only generate a valid config for `hub.KerasLayer(handle, ...)`\"\n",
    "          \"that uses a string `handle`.\\n\\n\"\n",
    "          \"Got `type(handle)`: {}\".format(type(self._handle)))\n",
    "    config[\"handle\"] = self._handle\n",
    "\n",
    "    if hasattr(self, \"_output_shape\"):\n",
    "      output_shape = _convert_nest_from_shapes(self._output_shape)\n",
    "      try:\n",
    "        json.dumps(output_shape)\n",
    "      except TypeError:\n",
    "        raise ValueError(\n",
    "            \"hub.KerasLayer(..., output_shape=) is not json-serializable.\\n\"\n",
    "            \"Got value: {}\".format(output_shape))\n",
    "      config[\"output_shape\"] = output_shape\n",
    "\n",
    "    if self._arguments:\n",
    "      # Raise clear errors for non-serializable arguments.\n",
    "      for key, value in self._arguments.items():\n",
    "        try:\n",
    "          json.dumps(value)\n",
    "        except TypeError:\n",
    "          raise ValueError(\n",
    "              \"`hub.KerasLayer(..., arguments)` contains non json-serializable\"\n",
    "              \"values in key: {}\".format(key))\n",
    "      config[\"arguments\"] = self._arguments\n",
    "\n",
    "    if self._signature:\n",
    "      config[\"signature\"] = self._signature\n",
    "    if self._output_key:\n",
    "      config[\"output_key\"] = self._output_key\n",
    "    if self._signature_outputs_as_dict:\n",
    "      config[\"signature_outputs_as_dict\"] = self._signature_outputs_as_dict\n",
    "\n",
    "    # self._load_options is not stored in the config. Instead, the load\n",
    "    # options passed at the time when this layer gets reloaded from its config\n",
    "    # are applied to its own loading as well. That is because the only\n",
    "    # load option available at this time (July 2020) is\n",
    "    # `experimental_io_device`, which relates to the loading environment,\n",
    "    # and not to the interpretation of the loaded SavedModel.\n",
    "\n",
    "    return config\n",
    "\n",
    "  @property\n",
    "  def resolved_object(self):\n",
    "    \"\"\"Returns the callable object to which `handle` resolved in `__init__`.\"\"\"\n",
    "    return self._func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.training.tracking import data_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_hub import module_v2\n",
    "def load_module(handle, tags=None, load_options=None):\n",
    "  if callable(handle):\n",
    "    if tags is not None:\n",
    "      raise ValueError(\"Passing a callable handle is mutually exclusive \"\n",
    "                       \"with setting tags.\")\n",
    "    if load_options is not None:\n",
    "      raise ValueError(\"Passing a callable handle is mutually exclusive \"\n",
    "                       \"with setting load_options.\")\n",
    "    return handle\n",
    "  else:\n",
    "    try:\n",
    "      # pylint: disable=g-import-not-at-top\n",
    "      # pylint: disable=g-direct-tensorflow-import\n",
    "      from tensorflow.python.keras.saving.saved_model import load_context\n",
    "      set_load_options = load_options or load_context.get_load_options()\n",
    "    except ImportError:  # Expected before TF2.5.\n",
    "      try:\n",
    "        # pylint: disable=g-import-not-at-top\n",
    "        # pylint: disable=g-direct-tensorflow-import\n",
    "        from tensorflow.python.saved_model import load_context\n",
    "        set_load_options = load_options or load_context.get_load_options()\n",
    "      except ImportError:  # Expected before TF2.4.\n",
    "        set_load_options = load_options\n",
    "    return module_v2.load(handle, tags=tags, options=set_load_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_has_training_argument(func):\n",
    "  \"\"\"Checks whether saved model has a `training` argument.\"\"\"\n",
    "  if not callable(func):\n",
    "    return False\n",
    "  fullargspec = tf_inspect.getfullargspec(func.__call__)\n",
    "  return (\"training\" in fullargspec.args or\n",
    "          \"training\" in fullargspec.kwonlyargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import tf_inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import smart_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1652\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.python.keras.models import model_from_yaml\n",
    "\n",
    "# 加载模型结构\n",
    "model = model_from_yaml(open('model_architecture_choosed.yaml').read(),custom_objects={'KerasLayer': KerasLayer})\n",
    "# model = model_from_json(open('../docs/keras/model_architecture.json').read())\n",
    "\n",
    "# 加载模型参数\n",
    "model.load_weights('model_weights16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 134s 828ms/step - loss: 1.7854 - acc: 0.1904 - val_loss: 1.7782 - val_acc: 0.2002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e7b553ca90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model00.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['acc'])\n",
    "model00.fit(\n",
    "    train_generator, \n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1652\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.python.keras.models import model_from_yaml\n",
    "\n",
    "# 加载模型结构\n",
    "model = model_from_yaml(open('model_architecture_choosed.yaml').read(),custom_objects={'KerasLayer': KerasLayer})\n",
    "# model = model_from_json(open('../docs/keras/model_architecture.json').read())\n",
    "\n",
    "# 加载模型参数\n",
    "model.load_weights('model_weights16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 202s 1s/step - loss: 0.3105 - acc: 0.8798 - val_loss: 0.3420 - val_acc: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e9821422b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['acc'])\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1652\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "model = model_from_yaml(open('model_architecture_choosed.yaml').read(),custom_objects={'KerasLayer': KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
